{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your lower bound here:\n",
    "zeta = -1807;        \n",
    "folder = ['data/6045/']\n",
    "example = ['NewExample1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import cplex  as CPX\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SecModelParameter ( CGLP_m, n, CGLP_rhs, CGLP_Coef,Br_var):\n",
    "    MultiplyVar=np.arange(Br_var+1,n).tolist()\n",
    "    Colij=dict()\n",
    "    k=n\n",
    "    for i in MultiplyVar:\n",
    "        for j in range (n):\n",
    "            if i!=j:\n",
    "                if (tuple([j,i]) in Colij)!=True:\n",
    "                    if i<j:\n",
    "                        Colij[tuple([i,j])]= k\n",
    "                        k=k+1\n",
    "                    else:\n",
    "                        Colij[tuple([j,i])]= k\n",
    "                        k=k+1\n",
    "    lenColij=len(Colij)+n\n",
    "    CompleteMatrix=[]\n",
    "    CompleteRHS=[]\n",
    "    for i in MultiplyVar:\n",
    "        for t in range (CGLP_m):\n",
    "            LineMatrix=np.zeros(lenColij)\n",
    "            for j in range (n):\n",
    "                if i==j:\n",
    "                    LineMatrix[j]= CGLP_Coef[t][j]\n",
    "                    LineMatrix[j]=LineMatrix[j]-CGLP_rhs[t]\n",
    "                    \n",
    "                if i<j:\n",
    "                    LineMatrix [Colij[tuple([i,j])]]=CGLP_Coef[t][j]\n",
    "                if i>j:\n",
    "                    LineMatrix [Colij[tuple([j,i])]]=CGLP_Coef[t][j]    \n",
    "            CompleteMatrix.append(LineMatrix)\n",
    "            CompleteRHS.append(0)\n",
    "\n",
    "\n",
    "\n",
    "            LineMatrix=np.zeros(lenColij)\n",
    "            for j in range (n):\n",
    "                if j==i:\n",
    "                    LineMatrix[i]= CGLP_rhs[t]\n",
    "                else:\n",
    "                    LineMatrix[j]= CGLP_Coef[t][j]\n",
    "                if i<j:\n",
    "                    LineMatrix [Colij[tuple([i,j])]]=-1*CGLP_Coef[t][j]\n",
    "                if i>j:\n",
    "                    LineMatrix [Colij[tuple([j,i])]]=-1*CGLP_Coef[t][j]   \n",
    "            CompleteMatrix.append(LineMatrix)   \n",
    "            CompleteRHS.append(CGLP_rhs[t])\n",
    "        \n",
    "        \n",
    "\n",
    "    for i in MultiplyVar:\n",
    "        for t in range (2*n):\n",
    "            LineMatrix=np.zeros(lenColij)\n",
    "            LineRHS=np.zeros(1)\n",
    "            if my_rhsUnit[t]==1:\n",
    "                for j in range (n):\n",
    "                    LineRHS= my_rhsUnit[t]\n",
    "                    if i==j:\n",
    "                        LineMatrix[j]= UnitMatrix[t][j]\n",
    "                        LineMatrix[j]=LineMatrix[j]-my_rhsUnit[t] \n",
    "                    if i<j:\n",
    "\n",
    "                        LineMatrix [Colij[tuple([i,j])]]=UnitMatrix[t][j]\n",
    "                    if i>j:\n",
    "\n",
    "                        LineMatrix [Colij[tuple([j,i])]]=UnitMatrix[t][j] \n",
    "\n",
    "            if all(k == 0 for k in LineMatrix)!=True:\n",
    "                CompleteMatrix.append(LineMatrix) \n",
    "                CompleteRHS.append(0)\n",
    "\n",
    "            LineMatrix=np.zeros(lenColij)\n",
    "            LineRHS=np.zeros(1)\n",
    "            for j in range (n):\n",
    "                LineRHS= my_rhsUnit[t]\n",
    "                if j==i:\n",
    "                    LineMatrix[i]= my_rhsUnit[t]\n",
    "                else:\n",
    "                    LineMatrix[j]=UnitMatrix[t][j]\n",
    "\n",
    "                if i<j:\n",
    "                    LineMatrix [Colij[tuple([i,j])]]=-1*UnitMatrix[t][j]\n",
    "                if i>j:\n",
    "                    LineMatrix [Colij[tuple([j,i])]]=-1*UnitMatrix[t][j]   \n",
    "\n",
    "            if all(k == 0 for k in LineMatrix)!=True:\n",
    "                CompleteMatrix.append(LineMatrix) \n",
    "                CompleteRHS.append(LineRHS)\n",
    "\n",
    "                    \n",
    "    return CompleteMatrix,CompleteRHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BB (m,n,A, my_obj,b, lx, ux, IntVars,my_colnames, zeta):\n",
    "    lp_solving=0\n",
    "    eps=0.001\n",
    "    extraeps=0.01\n",
    "    cLR = 0.06\n",
    "    Threshold = 0.6\n",
    "    branch_flag=-1\n",
    "    prev_Br_var=-2\n",
    "    Br_var=-1\n",
    "    node_numbers=0\n",
    "    Tol = 0.0000001;\n",
    "    LXS = np.array([np.copy(lx)]);\n",
    "    UXS = np.array([np.copy(ux)]);\n",
    "    ZS = np.array([100000]);\n",
    "    Br_order=np.array([-1])\n",
    "    x = [];\n",
    "    prev_zeta= zeta \n",
    "    nn = 1;\n",
    "    while 1==1:\n",
    "        f=list(np.where(ZS <= zeta + Tol)[0])\n",
    "        if len(f)>0:\n",
    "            LXS=np.delete(LXS, f, 0)\n",
    "            UXS=np.delete(UXS, f, 0)\n",
    "            ZS=np.delete(ZS, f)\n",
    "            Br_order=np.delete(Br_order,f)\n",
    "            nn = nn - len(f);\n",
    "        if nn==0:\n",
    "            break\n",
    "        lx1=LXS[0]\n",
    "        ux1=UXS[0] \n",
    "        LXS=np.delete(LXS, 0, 0)\n",
    "        UXS=np.delete(UXS, 0, 0)\n",
    "        ZS=np.delete(ZS, 0)\n",
    "        prev_Br_var=Br_var\n",
    "        Br_var=Br_order[0]\n",
    "        Br_order=np.delete(Br_order,0)\n",
    "        nn = nn - 1;\n",
    "        node_numbers=node_numbers+1\n",
    "        Lp_Relaxation = CPX.Cplex() \n",
    "        Lp_Relaxation.objective.set_sense(Lp_Relaxation.objective.sense.maximize)    \n",
    "        Lp_Relaxation.variables.add(obj = my_obj, lb=lx1, ub =ux1, names = my_colnames)\n",
    "        Lp_Relaxation.linear_constraints.add(lin_expr = my_coef, senses = 'L'*m, rhs = my_rhs) \n",
    "        Lp_Relaxation.parameters.simplex.display.set(0)\n",
    "        Lp_Relaxation.solve()\n",
    "\n",
    "        status= Lp_Relaxation.solution.get_status()\n",
    "        if status != 3:\n",
    "            xR= Lp_Relaxation.solution.get_values()\n",
    "            zR= Lp_Relaxation.solution.get_objective_value()\n",
    "        if status == 2:\n",
    "            check_unbound=BB (m,n,A, np.zeros[n],b, lx, ux, IntVars,my_colnames)\n",
    "            zR0= check_unbound[0]\n",
    "            if zR0==0:\n",
    "                zeta = math.inf\n",
    "                break\n",
    "        if (status == 3 or zR<=zeta + Tol):\n",
    "            continue \n",
    "\n",
    "        Fractions=np.abs(xR - np.round(xR))\n",
    "        maxf=max(Fractions)\n",
    "        if maxf <= Tol:     \n",
    "            x = xR;\n",
    "            zeta = zR;\n",
    "            continue;  \n",
    "\n",
    "    #####################################################################################################               \n",
    "        VarsValue=np.copy(lx1[0:Br_var+1])\n",
    "\n",
    "        if Br_var not in [-1,n-1]:\n",
    "            if Br_var>branch_flag or prev_zeta!=zeta: \n",
    "\n",
    "                if prev_zeta!=zeta:\n",
    "                    prev_zeta=zeta\n",
    "                    CGLP_rhs[-1]=-1*zeta\n",
    "\n",
    "                SecModelParameter_output=SecModelParameter(CGLP_m, n, CGLP_rhs, CGLP_Coef,Br_var)\n",
    "                CompleteMatrix=SecModelParameter_output[0]\n",
    "                CompleteRHS=SecModelParameter_output[1]\n",
    "                numrows = len(CompleteMatrix)    \n",
    "                numcols = len(CompleteMatrix[0])\n",
    "                my_lb=[0.0]*numrows\n",
    "                my_row=[1.0]*numrows\n",
    "\n",
    "                Fliped_CompleteMatrix_const=np.negative(np.array(CompleteMatrix)).T.tolist()\n",
    "\n",
    "                #####train\n",
    "                if Br_var>branch_flag:\n",
    "                    FinalCoeff=Fliped_CompleteMatrix_const[Br_var+1:]\n",
    "                    FinalBound=np.negative(np.eye(numrows, dtype=int)).tolist()\n",
    "                    FinalCoeff=FinalCoeff+FinalBound\n",
    "                    lenFinalCoeff=len(FinalCoeff)\n",
    "                    FinalCoeff=np.array(FinalCoeff)\n",
    "\n",
    "                    # negative of regular const class one\n",
    "                    X_trainset=np.negative(FinalCoeff)                    \n",
    "                    #one vector class one\n",
    "                    OnesVector=np.ones((lenFinalCoeff,numrows))\n",
    "                    newrow=FinalCoeff+OnesVector*eps \n",
    "                    X_trainset=np.concatenate((X_trainset,newrow), axis=0)\n",
    "                    # class zero\n",
    "                    for k in range(2):\n",
    "                        PosRandNum=np.random.uniform(1,10000,(lenFinalCoeff,numrows))  \n",
    "                        newrow=FinalCoeff-PosRandNum*extraeps \n",
    "                        X_trainset=np.concatenate((X_trainset,newrow), axis=0)\n",
    "                        \n",
    "                    X_trainset=preprocessing.normalize(X_trainset, axis=1, norm='l2')\n",
    "                    y_trainset=[1]*lenFinalCoeff*2+ [0]*lenFinalCoeff*2\n",
    "                    LR = LogisticRegression(C=cLR, solver= 'liblinear').fit(X_trainset,y_trainset)\n",
    "#                     cLR=cLR+0.005\n",
    "                branch_flag=Br_var\n",
    "\n",
    "                obj_mat=np.array(CompleteMatrix)[:,range(0,Br_var+1)]\n",
    "\n",
    "            obj=[]\n",
    "            for j in range (numrows):\n",
    "                obj.append(np.inner(obj_mat[j],VarsValue)-CompleteRHS[j])\n",
    "            X_testset=[obj/np.linalg.norm(obj)]\n",
    "            if (LR.predict_proba(X_testset)[:, 1] >= Threshold).astype(int):  \n",
    "                continue\n",
    "\n",
    "    #####################################################################################################                \n",
    "        indf=Br_var+1\n",
    "        nlx = np.array(np.copy(lx1));\n",
    "        nlx[indf] = 1;    \n",
    "        nux = np.array(np.copy(ux1));\n",
    "        nux[indf] = 0;\n",
    "        LXS=np.append(LXS,(lx1, nlx),axis=0)\n",
    "        UXS=np.append(UXS,(nux, ux1),axis=0)\n",
    "        ZS = np.append(ZS, (zR, zR));\n",
    "        Br_order=np.append(Br_order,(indf,indf))\n",
    "        nn = nn + 2    \n",
    "    return zeta,node_numbers,lp_solving  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for xx in ['python3/6045/']:\n",
    "    for yy in ['NewExample31']:\n",
    "        main_prob = CPX.Cplex(xx+yy+'.lp')\n",
    "        m=main_prob.linear_constraints.get_num()\n",
    "        CGLP_m=m+1\n",
    "        n=main_prob.variables.get_num()\n",
    "        my_rhs=np.array([])\n",
    "        CGLP_rhs=np.array([])\n",
    "        my_coef=[]\n",
    "        CGLP_Coef=[]\n",
    "\n",
    "        for i in range(m):\n",
    "            temp=[]\n",
    "            for j in range(n):\n",
    "                temp.append (main_prob.linear_constraints.get_coefficients(i,j))    \n",
    "            my_coef.append([list (range(n)),temp])\n",
    "            CGLP_Coef.append(temp)\n",
    "        \n",
    "        CGLP_Coef = np.vstack((CGLP_Coef, main_prob.objective.get_linear()))\n",
    "        CGLP_Coef[-1]=np.negative(CGLP_Coef[-1])\n",
    "        for i in range (m):\n",
    "            my_rhs=np.append(my_rhs,main_prob.linear_constraints.get_rhs(i))\n",
    "            CGLP_rhs=np.append(CGLP_rhs,main_prob.linear_constraints.get_rhs(i))\n",
    "        CGLP_rhs=np.append(CGLP_rhs,0)\n",
    "        my_obj= np.array(main_prob.objective.get_linear())\n",
    "        UnitMatrix=np.eye(n, dtype=int).tolist()+np.negative(np.eye(n, dtype=int)).tolist()\n",
    "        my_rhsUnit=[1]*n+[0]*n \n",
    "        IntVars=np.arange(n)\n",
    "        lx= [0.0]*n\n",
    "        ux=[1.0]*n\n",
    "        my_colnames=[]\n",
    "        for i in range(n):\n",
    "            my_colnames.append(\"x\"+str(i))  \n",
    "\n",
    "        time1=time.time()\n",
    "        output=BB (m,n,my_coef,my_obj,my_rhs, lx, ux, IntVars,my_colnames,zeta)               \n",
    "        time2=time.time()-time1\n",
    "\n",
    "        with open(xx+yy+'bb_greedy_optimality.txt', 'a') as f:\n",
    "            f.write('{}:{}\\n'.format('objective value',output[0]))\n",
    "            f.write('{}:{}\\n'.format('Number of explored node',output[1]))\n",
    "            f.write('{}:{}\\n'.format('Number of solved LPs',output[2]))\n",
    "            f.write('{}:{}\\n'.format('ElapsedTime',time2))\n",
    "        f.closed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
